# -*- coding: utf-8 -*-
"""Proj4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_1yMuq79qNKqP5hOLiCsBvfuD08_XSEO

#Introduction

This notebook focuses on forecasting weekly sales for various Walmart stores using the Chronos deep learning model. We begin by loading and preparing the sales data, converting it into a time series format suitable for Chronos, and applying a log transformation to optimize model performance. The core achievement is leveraging the Chronos model to generate 4 week ahead sales predictions, complete with confidence intervals. We then rigorously evaluate these forecasts using metrics like MAE, RMSE, and MAPE, revealing that while the model exhibits exceptional accuracy for some stores (e.g., MAPE under 2% for Store 30 and 33), performance varies

##Loading the Dataset
"""

import pandas as pd, os

CSV_PATH = "/content/drive/MyDrive/WALMART_SALES_DATA.csv"

df = pd.read_csv(CSV_PATH)

"""##Handle Missing Values"""

print("Missing values count per column:")
print(df.isnull().sum())

print("\nPercentage of missing values per column:")
print((df.isnull().sum() / len(df)) * 100)

print("\nData types of all columns:")
print(df.dtypes)

"""##Handle Outliers"""

Q1 = df['Weekly_Sales'].quantile(0.25)
Q3 = df['Weekly_Sales'].quantile(0.75)
IQR = Q3 - Q1

upper_bound = Q3 + 1.5 * IQR
lower_bound = Q1 - 1.5 * IQR

outliers = df[(df['Weekly_Sales'] < lower_bound) | (df['Weekly_Sales'] > upper_bound)]

print(f"First Quartile (Q1): {Q1}")
print(f"Third Quartile (Q3): {Q3}")
print(f"Interquartile Range (IQR): {IQR}")
print(f"Upper Bound for Outliers: {upper_bound}")
print(f"Lower Bound for Outliers: {lower_bound}")
print(f"\nNumber of outliers detected: {len(outliers)}")
print("\nFirst 5 outliers (if any):\n", outliers.head())

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.boxplot(y=df['Weekly_Sales'])
plt.title('Box Plot of Weekly Sales with Outliers')
plt.ylabel('Weekly Sales')
plt.grid(axis='y', linestyle='--')
plt.show()
print("Box plot showing the distribution of Weekly_Sales and detected outliers.")

"""##Load → convert to WEEKLY"""

df["Date"] = pd.to_datetime(df["Date"], format="%d-%m-%Y")

df_weekly = (
    df.groupby(["Store", pd.Grouper(key="Date", freq="W")])["Weekly_Sales"]
      .sum()
      .reset_index()
      .sort_values(["Store", "Date"])
)

"""##Log transform target (MUCH better for Chronos)"""

df_weekly["Sales_Log"] = np.log1p(df_weekly["Weekly_Sales"])

"""##Build Chronos time series format"""

time_series_data = []
for store_id, store_df in df_weekly.groupby("Store"):
    store_df = store_df.sort_values("Date")
    ts = {
        "item_id": store_id,
        "start": store_df["Date"].iloc[0],
        "target_values": torch.tensor(store_df["Sales_Log"].values, dtype=torch.float32),
    }
    time_series_data.append(ts)

"""##Chronos Installation"""

!pip install git+https://github.com/amazon-science/chronos-forecasting.git

from chronos import ChronosPipeline

pipeline = ChronosPipeline.from_pretrained(
    "amazon/chronos-t5-tiny",

)

device = "cuda" if torch.cuda.is_available() else "cpu"
pipeline.model.to(device)

prediction_length = 4     # 4 weeks ahead
num_samples = 200         # number of forecast samples

"""##Forecast weekly (log space → then invert)"""

all_store_forecasts = []

for ts in time_series_data:
    target = ts["target_values"]

    forecast = pipeline.predict(
        inputs=[target],
        prediction_length=prediction_length,
        num_samples=num_samples
    )
#forecast is list → take first element
    samples_log = forecast[0].numpy()     # shape: [200 samples, 4 weeks]

    # Invert log1p
    samples = np.expm1(samples_log)
    # Compute stats
    mean_fc = samples.mean(axis=0)
    low_fc  = np.percentile(samples, 5, axis=0)
    high_fc = np.percentile(samples, 95, axis=0)

    all_store_forecasts.append({
        "store_id": ts["item_id"],
        "mean": mean_fc,
        "low": low_fc,
        "high": high_fc
    })

# =====================================================
# 6. Print
# =====================================================
for fc in all_store_forecasts:
    print("\nStore:", fc["store_id"])
    print("Weekly forecast (mean):", fc["mean"])

"""##Visualise Forecast"""

import matplotlib.pyplot as plt
import holidays

# US holidays for marking
us_holidays = holidays.US(years=[2023, 2024, 2025])  # add years as needed

for fc in all_store_forecasts:
    store_id = fc["store_id"]

    # Actual data for this store
    store_df = df_weekly[df_weekly["Store"] == store_id].sort_values("Date")

    # Forecast dates (next 4 weeks after last date)
    last_date = store_df["Date"].max()
    forecast_dates = pd.date_range(start=last_date + pd.Timedelta(days=7), periods=prediction_length, freq='W')

    mean_fc = fc["mean"]
    low_fc = fc["low"]
    high_fc = fc["high"]

    plt.figure(figsize=(12,6))

    # Plot actual weekly sales
    plt.plot(store_df["Date"], store_df["Weekly_Sales"], label="Actual Weekly Sales", marker='o')

    # Plot forecast mean
    plt.plot(forecast_dates, mean_fc, '--', color='orange', label="Forecast Mean", marker='o')

    # Fill 90% CI
    plt.fill_between(forecast_dates, low_fc, high_fc, color='orange', alpha=0.2, label="90% CI")

    # Mark holidays
    for h in store_df["Date"]:
        if h in us_holidays:
            plt.axvline(h, color='red', linestyle=':', alpha=0.5)

    plt.title(f"Weekly Sales Forecast for Store {store_id}")
    plt.xlabel("Date")
    plt.ylabel("Weekly Sales")
    plt.legend()
    plt.grid(True)
    plt.show()

"""### Evaluate Forecast Performance"""

from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

# Helper: MAPE
def mean_absolute_percentage_error(y_true, y_pred):
    # avoid division by zero
    y_true_safe = np.where(y_true == 0, 1e-6, y_true)
    return np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100

print("=== Chronos Weekly Forecast Performance ===")

for fc in all_store_forecasts:
    store_id = fc["store_id"]

    # Actuals
    store_df = df_weekly[df_weekly["Store"] == store_id].sort_values("Date")
    actuals = store_df["Weekly_Sales"].values[-prediction_length:]

    # Forecast mean
    pred = fc["mean"]

    # Replace NaN or Inf with zeros (or you can use np.nanmean)
    actuals = np.nan_to_num(actuals, nan=0.0, posinf=0.0, neginf=0.0)
    pred = np.nan_to_num(pred, nan=0.0, posinf=0.0, neginf=0.0)

    # Compute metrics
    mae = mean_absolute_error(actuals, pred)
    rmse = np.sqrt(mean_squared_error(actuals, pred))
    mape = mean_absolute_percentage_error(actuals, pred)

    print(f"Store {store_id}: MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}%")

"""##Insights

####For several stores, the Chronos model demonstrated exceptional forecasting accuracy, as evidenced by very low Mean Absolute Percentage Error (MAPE) values. Notably, Store 30 achieved a MAPE of merely 1.91%, and Store 33 performed even better with a MAPE of 1.70%. These figures are highly encouraging, signifying that for these particular locations, the model's predictions deviated from actual sales by less than two percent on average. Such precision suggests that these stores likely exhibit more consistent and predictable sales patterns, or perhaps less volatility, making them ideal candidates for the Chronos model's current configuration. This high accuracy provides a solid foundation for operational planning and inventory management in these specific stores.



---
"""